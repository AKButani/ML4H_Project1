{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a472f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.0, 1: 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salom\\OneDrive\\Documents\\ML4H_Project1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.5674 - loss: 0.9677 - val_accuracy: 0.7533 - val_loss: 0.4840\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - accuracy: 0.7748 - loss: 0.7504 - val_accuracy: 0.7611 - val_loss: 0.4598\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 138ms/step - accuracy: 0.8042 - loss: 0.6680 - val_accuracy: 0.7736 - val_loss: 0.4479\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.8261 - loss: 0.5868 - val_accuracy: 0.8009 - val_loss: 0.4391\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8618 - loss: 0.5087 - val_accuracy: 0.8144 - val_loss: 0.4308\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.8858 - loss: 0.4487 - val_accuracy: 0.8124 - val_loss: 0.4372\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.9060 - loss: 0.3971 - val_accuracy: 0.7814 - val_loss: 0.5425\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.9074 - loss: 0.3713 - val_accuracy: 0.8117 - val_loss: 0.4907\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - accuracy: 0.9236 - loss: 0.3341 - val_accuracy: 0.8087 - val_loss: 0.5263\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.9291 - loss: 0.3353 - val_accuracy: 0.8074 - val_loss: 0.5273\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.9582 - loss: 0.2327 - val_accuracy: 0.8224 - val_loss: 0.5160\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9623 - loss: 0.2193 - val_accuracy: 0.8214 - val_loss: 0.5758\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9661 - loss: 0.1828 - val_accuracy: 0.8222 - val_loss: 0.5850\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9668 - loss: 0.1973 - val_accuracy: 0.8129 - val_loss: 0.6015\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.9656 - loss: 0.2349 - val_accuracy: 0.8224 - val_loss: 0.5856\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7999 - loss: 0.4548\n",
      "Unidirectional LSTM Test Loss: 0.447236031293869, Accuracy: 0.809904932975769\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "True Positives with Unidirectional (Deaths correctly predicted): 345\n",
      "False Negatives with Unidirectional (Deaths incorrectly predicted): 240\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "AUROC: 0.8134783795492849\n",
      "AUPRC: 0.4423428051222006\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Predictions saved to 'unidirectional_predictions.parquet'\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salom\\OneDrive\\Documents\\ML4H_Project1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6953 - loss: 0.9085 - val_accuracy: 0.7390 - val_loss: 0.4953\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.7822 - loss: 0.6929 - val_accuracy: 0.7533 - val_loss: 0.4723\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.8199 - loss: 0.5876 - val_accuracy: 0.7779 - val_loss: 0.4580\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 213ms/step - accuracy: 0.8586 - loss: 0.4632 - val_accuracy: 0.7884 - val_loss: 0.4542\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 184ms/step - accuracy: 0.8964 - loss: 0.3481 - val_accuracy: 0.8024 - val_loss: 0.4990\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9131 - loss: 0.2961 - val_accuracy: 0.7931 - val_loss: 0.5402\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9388 - loss: 0.2392 - val_accuracy: 0.8194 - val_loss: 0.5246\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.9496 - loss: 0.1964 - val_accuracy: 0.8254 - val_loss: 0.6100\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.9712 - loss: 0.1284 - val_accuracy: 0.8272 - val_loss: 0.6509\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9862 - loss: 0.0669 - val_accuracy: 0.8199 - val_loss: 0.7204\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.9788 - loss: 0.0970 - val_accuracy: 0.8069 - val_loss: 0.7613\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.9809 - loss: 0.0787 - val_accuracy: 0.7944 - val_loss: 0.9050\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.9689 - loss: 0.1300 - val_accuracy: 0.8104 - val_loss: 0.7718\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.9812 - loss: 0.0680 - val_accuracy: 0.8212 - val_loss: 0.7605\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8007 - loss: 0.4625\n",
      "\n",
      "Bidirectional LSTM Test Performance:\n",
      "Loss: 0.4463230073451996, Accuracy: 0.807153582572937\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "AUROC Bidirectional: 0.8058449217546787\n",
      "AUPRC Bidirectional: 0.4273327938642135\n",
      "Predictions saved to 'bidirectional_predictions.parquet'\n",
      "True Positives with bidirectional (Deaths correctly predicted): 325\n",
      "False Negatives with bidirectional (Deaths incorrectly predicted): 260\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
      "\n",
      "Aggregated Output Strategies:\n",
      "Mean Prediction: [0.2422247]\n",
      "Max Prediction: [0.9925824]\n",
      "Last Prediction: [0.08811452 0.03757531 0.60100305 ... 0.024933   0.03954733 0.32773533]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pyarrow  # Required for saving parquet files\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import random\n",
    "\n",
    "seed = 42  # Set the seed for reproducibility\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)  # For NumPy (if you use NumPy anywhere)\n",
    "random.seed(seed)  # For Python's built-in random module (if you use it anywhere)\n",
    "\n",
    "# Load the datasets\n",
    "def load_datasets():\n",
    "    train_set = pd.read_parquet('loaded_data/a_patient_data_processed_cluster.parquet')\n",
    "    test_set = pd.read_parquet('loaded_data/c_patient_data_processed_cluster.parquet')\n",
    "    validation_set = pd.read_parquet('loaded_data/b_patient_data_processed_cluster.parquet')\n",
    "    return train_set, test_set, validation_set\n",
    "\n",
    "def prepare_lstm_data(df, target_column, time_column='Time'):\n",
    "    if 'ICUType' in df.columns:\n",
    "        df = df.drop(columns=['ICUType'])\n",
    "\n",
    "    X, y = [], []\n",
    "    for patient_id, group in df.groupby('RecordID'):\n",
    "        group = group.sort_values(time_column)\n",
    "        features = group.drop(columns=[target_column, 'RecordID', time_column]).values\n",
    "        target = group[target_column].iloc[0]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    \n",
    "    # Pad sequences so that all sequences have the same length\n",
    "    X_padded = pad_sequences(X, padding='post', dtype='float32')\n",
    "    return X_padded, np.array(y)\n",
    "\n",
    "# Create Unidirectional LSTM Model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create Bidirectional LSTM Model\n",
    "def create_bidirectional_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape),\n",
    "        Bidirectional(LSTM(32)),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Aggregate LSTM outputs\n",
    "def aggregate_lstm_outputs(predictions):\n",
    "    mean_pred = np.mean(predictions, axis=0)\n",
    "    max_pred = np.max(predictions, axis=0)\n",
    "    last_pred = predictions[:, -1]\n",
    "    return {\n",
    "        'mean': mean_pred,\n",
    "        'max': max_pred,\n",
    "        'last': last_pred\n",
    "    }\n",
    "\n",
    "# Plot Loss and Accuracy\n",
    "def plot_training_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} - Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"Accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    train_set, test_set, validation_set = load_datasets()\n",
    "    X_train, y_train = prepare_lstm_data(train_set, target_column='In-hospital_death')\n",
    "    X_test, y_test = prepare_lstm_data(test_set, target_column='In-hospital_death')\n",
    "    X_val, y_val = prepare_lstm_data(validation_set, target_column='In-hospital_death')\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    # Alternatively, manually set class weights\n",
    "    class_weight_dict = {0: 1.0, 1: 5.0}  # Penalize misclassifying deaths 5x more\n",
    "    print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "    # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    unidirectional_model = create_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    unidirectional_history = unidirectional_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        #validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    unidirectional_results = unidirectional_model.evaluate(X_test, y_test)\n",
    "    print(f\"Unidirectional LSTM Test Loss: {unidirectional_results[0]}, Accuracy: {unidirectional_results[1]}\")\n",
    "\n",
    "    y_pred = (unidirectional_model.predict(X_test) > 0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(f\"True Positives with Unidirectional (Deaths correctly predicted): {tp}\")\n",
    "    print(f\"False Negatives with Unidirectional (Deaths incorrectly predicted): {fn}\")\n",
    "\n",
    "    y_pred_prob = unidirectional_model.predict(X_test).flatten()\n",
    "    # Compute AUROC and AUPRC\n",
    "    auroc = roc_auc_score(y_test, y_pred_prob)\n",
    "    auprc = average_precision_score(y_test, y_pred_prob)\n",
    "    print(f\"AUROC: {auroc}\")\n",
    "    print(f\"AUPRC: {auprc}\")\n",
    "\n",
    "    df_predictions = pd.DataFrame({\n",
    "        'True_Value': y_test,\n",
    "        \"Prob_death\": unidirectional_model.predict(X_test).flatten(),\n",
    "        'Predicted_Value': y_pred.flatten()\n",
    "    })\n",
    "    df_predictions.to_parquet(\"unidirectional_predictions.parquet\", index=False)\n",
    "    print(\"Predictions saved to 'unidirectional_predictions.parquet'\")\n",
    "\n",
    "    plot_training_history(unidirectional_history, 'Unidirectional LSTM')\n",
    "\n",
    "    bidirectional_model = create_bidirectional_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    bidirectional_history = bidirectional_model.fit(\n",
    "        X_train, y_train,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    bidirectional_results = bidirectional_model.evaluate(X_test, y_test)\n",
    "    print(\"\\nBidirectional LSTM Test Performance:\")\n",
    "    print(f\"Loss: {bidirectional_results[0]}, Accuracy: {bidirectional_results[1]}\")\n",
    "\n",
    "    y_pred_bi = (bidirectional_model.predict(X_test) > 0.5).astype(int)\n",
    "    df_predictions_bi = pd.DataFrame({\n",
    "        'True_Value': y_test,\n",
    "        \"Prob_death\": bidirectional_model.predict(X_test).flatten(),\n",
    "        'Predicted_Value': y_pred_bi.flatten()\n",
    "    })\n",
    "\n",
    "    y_pred_prob_bi = bidirectional_model.predict(X_test).flatten()\n",
    "    # Compute AUROC and AUPRC\n",
    "    auroc_bi = roc_auc_score(y_test, y_pred_prob_bi)\n",
    "    auprc_bi = average_precision_score(y_test, y_pred_prob_bi)\n",
    "    print(f\"AUROC Bidirectional: {auroc_bi}\")\n",
    "    print(f\"AUPRC Bidirectional: {auprc_bi}\")\n",
    "\n",
    "    df_predictions_bi.to_parquet(\"bidirectional_predictions.parquet\", index=False)\n",
    "    print(\"Predictions saved to 'bidirectional_predictions.parquet'\")\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_bi).ravel()\n",
    "    print(f\"True Positives with bidirectional (Deaths correctly predicted): {tp}\")\n",
    "    print(f\"False Negatives with bidirectional (Deaths incorrectly predicted): {fn}\")\n",
    "\n",
    "    unidirectional_predictions = unidirectional_model.predict(X_test)\n",
    "    aggregated_outputs = aggregate_lstm_outputs(unidirectional_predictions)\n",
    "    print(\"\\nAggregated Output Strategies:\")\n",
    "    for method, prediction in aggregated_outputs.items():\n",
    "        print(f\"{method.capitalize()} Prediction: {prediction}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
