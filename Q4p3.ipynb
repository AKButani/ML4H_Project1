{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e015089-048b-4eb7-aefe-6d332dd699f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "seed = 42 # Set the seed for reproducibility\n",
    "torch.manual_seed(seed) # For PyTorch\n",
    "torch.cuda.manual_seed_all(seed)  # If you're using GPU\n",
    "np.random.seed(seed) # For NumPy (if you use NumPy anywhere)\n",
    "random.seed(seed) # For Python's built-in random module (if you use it anywhere)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9145382-2c3a-49d7-afd4-7ef0a96955a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ===============================\n",
    "# Data Loading and Preprocessing\n",
    "# ===============================\n",
    "\n",
    "def load_datasets():\n",
    "    \"\"\"Load and preprocess train and test datasets\"\"\"\n",
    "    train_set = pd.read_parquet('loaded_data/a_patient_data_processed_cluster.parquet')\n",
    "    test_set = pd.read_parquet('loaded_data/c_patient_data_processed_cluster.parquet')\n",
    "    return train_set, test_set\n",
    "\n",
    "def pad_to_fixed_length(tensor, length=49):\n",
    "    \"\"\"Pad time series data to a fixed length\"\"\"\n",
    "    current_length = tensor.size(0)\n",
    "    if current_length < length:\n",
    "        padding = torch.zeros((length - current_length, tensor.size(1)))\n",
    "        return torch.cat([tensor, padding], dim=0)\n",
    "    else:\n",
    "        return tensor\n",
    "\n",
    "def process_dataframe(df):\n",
    "    \"\"\"Process dataframe to prepare for embedding generation\"\"\"\n",
    "    feature_columns = [col for col in df.columns if col not in [\"RecordID\", \"In-hospital_death\", \"ICUType\"]]\n",
    "    list_of_patient_data = []\n",
    "    patient_labels = []\n",
    "    grouped = df.groupby(\"RecordID\")\n",
    "    \n",
    "    for record_id, group in grouped:\n",
    "        # Extract features and labels\n",
    "        group_data = group[feature_columns].values\n",
    "        group_tensor = torch.tensor(group_data, dtype=torch.float32)\n",
    "        group_tensor_fixed = pad_to_fixed_length(group_tensor, length=49)\n",
    "        \n",
    "        # Keep the RecordID intact\n",
    "        patient_data = pd.DataFrame(group_tensor_fixed.numpy(), columns=feature_columns)\n",
    "        patient_data['RecordID'] = record_id  # Add the RecordID as a column\n",
    "        \n",
    "        list_of_patient_data.append(patient_data)\n",
    "        # For the label, we assume that if any timestep indicates death, the patient is labeled as death (1)\n",
    "        patient_labels.append(group[\"In-hospital_death\"].max())\n",
    "    \n",
    "    # Combine all the patient data\n",
    "    final_df = pd.concat(list_of_patient_data, ignore_index=True)\n",
    "    final_labels = pd.DataFrame(patient_labels, columns=[\"In-hospital_death\"])\n",
    "    final_labels.index = [id for id in grouped.groups.keys()]  # Set RecordID as index\n",
    "    \n",
    "    return final_df, final_labels\n",
    "\n",
    "# ===============================\n",
    "# Embedding Generation Functions\n",
    "# ===============================\n",
    "\n",
    "def load_chronos_pipeline():\n",
    "    \"\"\"Load the Chronos pipeline for time series embedding\"\"\"\n",
    "    pipeline = ChronosPipeline.from_pretrained(\n",
    "        \"amazon/chronos-t5-small\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "def get_embedding_for_variable(variable_data, pipeline):\n",
    "    \"\"\"Generate an embedding for a single time series variable\"\"\"\n",
    "    # Extract the relevant column and convert to tensor\n",
    "    context = torch.tensor(variable_data.values, dtype=torch.float32)\n",
    "    context = context.unsqueeze(0)  # Add batch dimension\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings, _ = pipeline.embed(context)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def get_patient_embedding(patient_data, patient_id, pipeline, aggregation=\"mean\"):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a patient by aggregating across all variables\n",
    "    \n",
    "    Args:\n",
    "        patient_data: DataFrame containing patient data\n",
    "        patient_id: RecordID for the patient\n",
    "        pipeline: Chronos pipeline for embedding generation\n",
    "        aggregation: Method to aggregate embeddings (\"mean\" or None)\n",
    "                     If None, returns per-variable embeddings for smart aggregation\n",
    "    \"\"\"\n",
    "    # Filter data for the specific patient\n",
    "    patient_df = patient_data[patient_data['RecordID'] == patient_id]\n",
    "    \n",
    "    # Create a list to store embeddings for each variable\n",
    "    embeddings = []\n",
    "    \n",
    "    # Iterate over each variable (excluding RecordID and Time)\n",
    "    for column in patient_df.columns:\n",
    "        if column != \"RecordID\" and column != \"Time\":\n",
    "            # Get the embedding for the current variable\n",
    "            variable_data = patient_df[column]\n",
    "            embedding = get_embedding_for_variable(variable_data, pipeline)\n",
    "            embeddings.append(embedding)\n",
    "    \n",
    "    # Return per-variable embeddings if requested\n",
    "    if aggregation is None:\n",
    "        return torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    # Convert the list of embeddings into a tensor and compute the average\n",
    "    embeddings_tensor = torch.cat(embeddings, dim=0)\n",
    "    if aggregation == \"mean\":\n",
    "        aggregated_embedding = torch.mean(embeddings_tensor, dim=0, keepdim=True)\n",
    "\n",
    "    #print(\"size\")\n",
    "    #print(aggregated_embedding.size())\n",
    "    return aggregated_embedding\n",
    "\n",
    "def generate_all_embeddings(patient_data, labels, pipeline, file_path, aggregation=\"mean\", batch_size=10):\n",
    "    \"\"\"\n",
    "    Generate embeddings for all patients in the dataset\n",
    "    \n",
    "    Args:\n",
    "        patient_data: DataFrame containing all patient data\n",
    "        labels: DataFrame containing patient labels\n",
    "        pipeline: Chronos pipeline for embedding generation\n",
    "        file_path: Path to save embeddings\n",
    "        aggregation: Method to aggregate embeddings across variables\n",
    "        batch_size: Number of patients to process before saving\n",
    "    \"\"\"\n",
    "    all_patient_embeddings = {}\n",
    "    all_patient_ids = patient_data['RecordID'].unique()\n",
    "    \n",
    "    # Resume from previous progress if file exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading existing embeddings from {file_path}\")\n",
    "        existing_embeddings = torch.load(file_path, weights_only=False)\n",
    "        all_patient_embeddings.update(existing_embeddings)\n",
    "        \n",
    "        # Filter out already processed patients\n",
    "        processed_ids = set(all_patient_embeddings.keys())\n",
    "        all_patient_ids = [id for id in all_patient_ids if id not in processed_ids]\n",
    "        print(f\"Resuming from {len(processed_ids)} already processed patients\")\n",
    "    \n",
    "    # Process remaining patients\n",
    "    total_patients = len(all_patient_ids)\n",
    "    print(f\"Processing embeddings for {total_patients} patients\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, patient_id in enumerate(tqdm(all_patient_ids)):\n",
    "        # Get the embedding for the current patient\n",
    "        patient_embedding = get_patient_embedding(patient_data, patient_id, pipeline, aggregation)\n",
    "        \n",
    "        # Store the embedding\n",
    "        all_patient_embeddings[patient_id] = patient_embedding\n",
    "        \n",
    "        # Save periodically\n",
    "        if (i + 1) % batch_size == 0 or (i + 1) == total_patients:\n",
    "            torch.save(all_patient_embeddings, file_path)\n",
    "            \n",
    "            # Print progress\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = (elapsed / (i + 1)) * (total_patients - i - 1)\n",
    "            print(f\"Processed {i+1}/{total_patients} patients. \"\n",
    "                  f\"Elapsed: {elapsed/60:.1f} min. \"\n",
    "                  f\"Remaining: {remaining/60:.1f} min.\")\n",
    "    \n",
    "    print(f\"All embeddings saved to {file_path}\")\n",
    "    return all_patient_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aec43c-a5cd-4f38-aa5b-3a8d9dc637ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# Linear Probe Implementation\n",
    "# ===============================\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"Simple linear probe for classification\"\"\"\n",
    "        super(LinearProbe, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "def prepare_embedding_dataset(embeddings_dict, labels_df):\n",
    "    \"\"\"Prepare embeddings and labels for model training\"\"\"\n",
    "    record_ids = list(embeddings_dict.keys())\n",
    "    \n",
    "    # Filter to only include record IDs that have labels\n",
    "    valid_record_ids = [rid for rid in record_ids if rid in labels_df.index]\n",
    "    \n",
    "    # Stack embeddings and get corresponding labels\n",
    "    embeddings_list = [embeddings_dict[rid].squeeze(0) for rid in valid_record_ids]\n",
    "    labels_list = [labels_df.loc[rid, \"In-hospital_death\"] for rid in valid_record_ids]\n",
    "    \n",
    "    X = torch.stack(embeddings_list)\n",
    "    y = torch.tensor(labels_list, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return X, y, valid_record_ids\n",
    "\n",
    "def train_linear_probe(train_embeddings, train_labels, val_embeddings=None, val_labels=None, \n",
    "                      num_epochs=100, lr=0.001, batch_size=32, early_stopping=10):\n",
    "    \"\"\"Train a linear probe on embeddings\"\"\"\n",
    "    # Prepare datasets\n",
    "    #X_train, y_train, _ = prepare_embedding_dataset(train_embeddings, train_labels)\n",
    "    X_train = torch.stack(list(train_embeddings.values()))  # Stack all patient embeddings into a tensor\n",
    "\n",
    "    # Ensure the input data (X_train) is of type float32\n",
    "    X_train = X_train.float()\n",
    "    X_train_flat = X_train.view(X_train.size(0), -1)\n",
    "    X_train_flat= X_train_flat.to(device)\n",
    "    y_train = train_labels.to(device)\n",
    "    X_test_flat = X_train_flat.to(device)  # Use the same data for testing (adjust as per your actual data)\n",
    "    y_test = train_labels.to(device)  # Same target labels for testing\n",
    "    X_test_flat = X_test_flat.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "   # print(X_train_flat)\n",
    "    #print(\"X_train_flat.size()\")\n",
    "   # print(X_train_flat.size())\n",
    "\n",
    "    # Create model\n",
    "    #input_dim = X_train.shape[1]\n",
    "    input_dim = 50*512\n",
    "   #print(\"input_dim\")\n",
    "    #print(input_dim)\n",
    "    model = LinearProbe(input_dim).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataset = TensorDataset(X_train_flat, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Validation data\n",
    "    has_validation = val_embeddings is not None and val_labels is not None\n",
    "    if has_validation:\n",
    "        X_val, y_val, _ = prepare_embedding_dataset(val_embeddings, val_labels)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            #inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "            targets = targets.unsqueeze(1)\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        if has_validation:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_targets = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    targets = targets.unsqueeze(1)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_loss += loss.item()\n",
    "                    all_preds.append(outputs.cpu())\n",
    "                    all_targets.append(targets.cpu())\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), 'best_linear_probe.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_targets = torch.cat(all_targets).numpy()\n",
    "            val_auc = roc_auc_score(all_targets, all_preds)\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, '\n",
    "                  f'Val AUC: {val_auc:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}')\n",
    "    \n",
    "    # Load best model if validation was used\n",
    "    if has_validation:\n",
    "        model.load_state_dict(torch.load('best_linear_probe.pth'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "def evaluate_model(model, embeddings_dict, labels_df):\n",
    "    \"\"\"Evaluate model on test data including AUPRC\"\"\"\n",
    "    # Prepare test data\n",
    "    X_test = torch.stack(list(embeddings_dict.values()))  # Stack all patient embeddings into a tensor\n",
    "    X_test = X_test.float()  # Ensure the input data is of type float32\n",
    "    X_test_flat = X_test.view(X_test.size(0), -1)\n",
    "    X_test_flat = X_test_flat.to(device)\n",
    "    \n",
    "    y_test = labels_df.to(device)  # Target labels for testing\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_flat)\n",
    "        probs = predictions.cpu().numpy()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        y_true = y_test.cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc = roc_auc_score(y_true, probs)\n",
    "    accuracy = accuracy_score(y_true, preds)\n",
    "    precision = precision_score(y_true, preds)\n",
    "    recall = recall_score(y_true, preds)\n",
    "    f1 = f1_score(y_true, preds)\n",
    "    auprc = average_precision_score(y_true, probs)  # Compute AUPRC\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUPRC: {auprc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"auc\": auc,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"auprc\": auprc,\n",
    "        \"predictions\": probs,\n",
    "        \"true_labels\": y_true\n",
    "    }\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Smart Aggregation Model\n",
    "# ===============================\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        \"\"\"\n",
    "        Channel attention network that learns weights for different variables\n",
    "        \n",
    "        Args:\n",
    "            embedding_dim: Dimension of each variable's embedding\n",
    "        \"\"\"\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, embeddings_per_variable):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings_per_variable: Tensor of shape [num_variables, embedding_dim]\n",
    "        \"\"\"\n",
    "        # Calculate attention score for each variable\n",
    "        attention_scores = self.attention(embeddings_per_variable)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        \n",
    "        # Apply attention weights\n",
    "        weighted_embeddings = embeddings_per_variable * attention_weights\n",
    "        \n",
    "        # Sum across variables\n",
    "        aggregated_embedding = torch.sum(weighted_embeddings, dim=0)\n",
    "        \n",
    "        return aggregated_embedding, attention_weights\n",
    "\n",
    "class SmartAggregationModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_variables=41):\n",
    "        \"\"\"\n",
    "        Model that learns to intelligently aggregate variable embeddings\n",
    "        \n",
    "        Args:\n",
    "            embedding_dim: Dimension of each variable's embedding\n",
    "            num_variables: Number of time series variables\n",
    "        \"\"\"\n",
    "        super(SmartAggregationModel, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(embedding_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape [batch_size, num_variables, embedding_dim]\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        outputs = []\n",
    "        attention_weights_list = []\n",
    "        \n",
    "        # Process each sample in the batch\n",
    "        for i in range(batch_size):\n",
    "            # Get variable embeddings for this sample\n",
    "            embeddings_per_variable = x[i]\n",
    "            \n",
    "            # Apply channel attention\n",
    "            aggregated, attention_weights = self.channel_attention(embeddings_per_variable)\n",
    "            \n",
    "            # Classify\n",
    "            output = self.classifier(aggregated)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            attention_weights_list.append(attention_weights)\n",
    "        \n",
    "        # Combine results\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        attention_weights = torch.stack(attention_weights_list)\n",
    "        \n",
    "        return outputs, attention_weights\n",
    "\n",
    "def generate_variable_embeddings(patient_data, record_ids, pipeline, checkpoint_file = \"\", checkpoint_interval=100):\n",
    "    \"\"\"Generate per-variable embeddings for smart aggregation\"\"\"\n",
    "    all_patient_embeddings = {}\n",
    "    \n",
    "    for idx, patient_id in  enumerate(tqdm(record_ids)):\n",
    "        # Filter data for this patient\n",
    "        patient_df = patient_data[patient_data['RecordID'] == patient_id]\n",
    "        \n",
    "        variable_embeddings = []\n",
    "        for column in patient_df.columns:\n",
    "            if column != \"RecordID\" and column != \"Time\":\n",
    "                # Get the embedding for the current variable\n",
    "                variable_data = patient_df[column]\n",
    "                context = torch.tensor(variable_data.values, dtype=torch.float32).unsqueeze(0)\n",
    "                #print(len(context))\n",
    "                with torch.no_grad():\n",
    "                    embedding, _ = pipeline.embed(context)\n",
    "                variable_embeddings.append(embedding.squeeze(0))\n",
    "        \n",
    "        # Stack embeddings for all variables [num_variables, embedding_dim]\n",
    "        all_patient_embeddings[patient_id] = torch.stack(variable_embeddings)\n",
    "\n",
    "        # Checkpoint: save every checkpoint_interval iterations\n",
    "        #if checkpoint_file and (idx + 1) % checkpoint_interval == 0:\n",
    "            #torch.save(all_patient_embeddings, checkpoint_file)\n",
    "            #print(f\"Checkpoint saved after processing {idx + 1} patients.\")\n",
    "    \n",
    "    return all_patient_embeddings\n",
    "\n",
    "def prepare_variable_embeddings_dataset(embeddings_dict, labels):\n",
    "    record_ids = list(embeddings_dict.keys())\n",
    "    \n",
    "    # Check if labels is a DataFrame or a tensor\n",
    "    if hasattr(labels, 'index'):\n",
    "        # If it's a DataFrame, filter based on index\n",
    "        valid_record_ids = [rid for rid in record_ids if rid in labels.index]\n",
    "        embeddings_list = [embeddings_dict[rid] for rid in valid_record_ids]\n",
    "        labels_tensor = torch.tensor(labels.loc[valid_record_ids].values)\n",
    "    else:\n",
    "        # Assume labels is a tensor and order matches record_ids\n",
    "        embeddings_list = [embeddings_dict[rid] for rid in record_ids]\n",
    "        labels_tensor = labels\n",
    "        valid_record_ids = record_ids\n",
    "    \n",
    "    return torch.stack(embeddings_list), labels_tensor, valid_record_ids\n",
    "\n",
    "def train_smart_aggregation_model(train_embeddings, train_labels, val_embeddings=None, val_labels=None,\n",
    "                                 num_epochs=100, lr=0.001, batch_size=32, early_stopping=10, class_weights=(1.0, 5.0)):\n",
    "    \"\"\"Train the smart aggregation model\"\"\"\n",
    "    # Prepare datasets\n",
    "    #X_train, y_train, _ = prepare_variable_embeddings_dataset(train_embeddings, train_labels)\n",
    "\n",
    "    X_train = torch.stack(list(train_embeddings.values()))  # Stack all patient embeddings into a tensor\n",
    "    print(\"here\")\n",
    "    print(X_train.size())\n",
    "    print(len(X_train))\n",
    "    # Ensure the input data (X_train) is of type float32\n",
    "    X_train = X_train.float()\n",
    "    X_train_flat = X_train.mean(dim=2)\n",
    "    print(\"here2\")\n",
    "    print(X_train_flat.size())\n",
    "    X_train_flat= X_train_flat.to(device)\n",
    "    y_train = train_labels.float().to(device)\n",
    "    \n",
    "    # Get dimensions\n",
    "    num_variables = X_train.shape[1] # second shape dimension  [500, 40, 50, 512]\n",
    "    embedding_dim = 512\n",
    "    \n",
    "    # Create model\n",
    "    model = SmartAggregationModel(embedding_dim, num_variables).to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Create data loader\n",
    "    train_dataset = TensorDataset(X_train_flat, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Validation data\n",
    "    has_validation = val_embeddings is not None and val_labels is not None\n",
    "    if has_validation:\n",
    "        X_val, y_val, _ = prepare_variable_embeddings_dataset(val_embeddings, val_labels)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs)\n",
    "            #print(targets)\n",
    "            loss = criterion(outputs, targets)\n",
    "            pos_weight = torch.tensor(class_weights[1]).to(device)\n",
    "            neg_weight = torch.tensor(class_weights[0]).to(device)\n",
    "            sample_weights = torch.where(targets == 1, pos_weight, neg_weight)\n",
    "            loss = (loss * sample_weights).mean()\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        if has_validation:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_targets = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    sample_weights = torch.where(targets == 1, pos_weight, neg_weight)\n",
    "                    loss = (loss * sample_weights).mean()\n",
    "                    val_loss += loss.item()\n",
    "                    all_preds.append(outputs.cpu())\n",
    "                    all_targets.append(targets.cpu())\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(model.state_dict(), 'best_smart_aggregation.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= early_stopping:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_targets = torch.cat(all_targets).numpy()\n",
    "            val_auc = roc_auc_score(all_targets, all_preds)\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, '\n",
    "                  f'Val AUC: {val_auc:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}')\n",
    "    \n",
    "    # Load best model if validation was used\n",
    "    if has_validation:\n",
    "        model.load_state_dict(torch.load('best_smart_aggregation.pth'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_smart_aggregation_model(model, embeddings_dict, labels_df, threshold = 0.43):\n",
    "    \"\"\"Evaluate the smart aggregation model\"\"\"\n",
    "    # Prepare test data\n",
    "    X_test, y_test, record_ids = prepare_variable_embeddings_dataset(embeddings_dict, labels_df)\n",
    "    X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "    X_test = torch.stack(list(embeddings_dict.values()))  # Stack all patient embeddings into a tensor\n",
    "    print(\"here\")\n",
    "    print(X_test.size())\n",
    "    print(len(X_test))\n",
    "    # Ensure the input data (X_train) is of type float32\n",
    "    X_test = X_test.float()\n",
    "    X_test_flat = X_test.mean(dim=2)\n",
    "    print(\"here2\")\n",
    "    print(X_test_flat.size())\n",
    "    X_test_flat= X_test_flat.to(device)\n",
    "    y_test = labels_df.float().to(device)\n",
    "    \n",
    "    # Get dimensions\n",
    "    num_variables = X_test.shape[1] # second shape dimension  [500, 40, 50, 512]\n",
    "    embedding_dim = 512\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #predictions, attention_weights = model(X_test)\n",
    "        predictions, attention_weights = model(X_test_flat)\n",
    "        probs = predictions.cpu().numpy()\n",
    "        preds = (probs > threshold).astype(int)\n",
    "        y_true = y_test.cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc = roc_auc_score(y_true, probs)\n",
    "    accuracy = accuracy_score(y_true, preds)\n",
    "    precision = precision_score(y_true, preds)\n",
    "    recall = recall_score(y_true, preds)\n",
    "    f1 = f1_score(y_true, preds)\n",
    "    auprc = average_precision_score(y_true, probs)  # Compute AUPRC\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"auprc: {auprc:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Analyze attention weights\n",
    "    mean_attention = attention_weights.mean(dim=0).cpu().squeeze()\n",
    "    \n",
    "    return {\n",
    "        \"auc\": auc,\n",
    "        \"auprc\": auprc,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"predictions\": probs,\n",
    "        \"true_labels\": y_true,\n",
    "        \"attention_weights\": mean_attention.numpy()\n",
    "    }\n",
    "\n",
    "def visualize_attention_weights(attention_weights, feature_names):\n",
    "    \"\"\"Visualize the learned attention weights across variables\"\"\"\n",
    "    # Convert attention_weights to a tensor if it's not already one\n",
    "    if not isinstance(attention_weights, torch.Tensor):\n",
    "        attention_weights = torch.tensor(attention_weights)\n",
    "    \n",
    "    # Sort by weight values\n",
    "    sorted_idx = torch.argsort(attention_weights, descending=True)\n",
    "    sorted_weights = attention_weights[sorted_idx]\n",
    "    sorted_features = [feature_names[i] for i in sorted_idx.tolist()]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(sorted_features)), sorted_weights.numpy(), align='center')\n",
    "    plt.yticks(range(len(sorted_features)), sorted_features)\n",
    "    plt.xlabel('Attention Weight')\n",
    "    plt.title('Variable Importance (Attention Weights)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('variable_attention_weights.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0810a-90b0-4ed6-a516-99f8789b5ddb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# Main Execution\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    print(\"Starting ICU Patient Analysis Pipeline with Chronos Embeddings\")\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    train_df, test_df = load_datasets()\n",
    "    processed_train, train_labels = process_dataframe(train_df)\n",
    "    processed_test, test_labels = process_dataframe(test_df)\n",
    "    \n",
    "    # Step 2: Load Chronos pipeline\n",
    "    print(\"Loading Chronos pipeline...\")\n",
    "    pipeline = load_chronos_pipeline()\n",
    "    \n",
    "    # Extract feature names (excluding RecordID and Time)\n",
    "    feature_names = [col for col in processed_train.columns \n",
    "                     if col != \"RecordID\" and col != \"Time\"]\n",
    "    \n",
    "    # Step 3: Generate embeddings\n",
    "    print(\"\\n=== Task 1: Generate Patient Embeddings ===\")\n",
    "    \n",
    "    # Check if embeddings already exist\n",
    "    train_emb_file = 'train_embeddings_linear.pth'\n",
    "    test_emb_file = 'test_embeddings_linear.pth'\n",
    "    \n",
    "    if os.path.exists(train_emb_file):\n",
    "        print(\"Loading pre-computed embeddings train...\")\n",
    "        train_embeddings = torch.load(train_emb_file, weights_only=False)\n",
    "    else:\n",
    "        print(\"Generating embeddings for training data...\")\n",
    "        train_embeddings = generate_all_embeddings(\n",
    "            processed_train, train_labels, pipeline, train_emb_file)\n",
    "\n",
    "    if os.path.exists(test_emb_file):\n",
    "        print(\"Loading pre-computed embeddings test...\")\n",
    "        test_embeddings = torch.load(test_emb_file, weights_only=False)\n",
    "    else:\n",
    "        print(\"Generating embeddings for testing data...\")\n",
    "        test_embeddings = generate_all_embeddings(\n",
    "            processed_test, test_labels, pipeline, test_emb_file)\n",
    "\n",
    "    #print(train_embeddings)\n",
    "    \n",
    "    df_training = pd.read_parquet(\"loaded_data/a_patient_data_processed_cluster.parquet\", engine='pyarrow')\n",
    "    df_training.head()\n",
    "    print(df_training.columns)\n",
    "    timestamp_count = df_training.groupby('RecordID')['Time'].nunique()\n",
    "    print(timestamp_count)\n",
    "    # check if ICUType is a column\n",
    "    columns_to_check = ['ICUType', 'In-hospital_death']\n",
    "    missing_columns = [col for col in columns_to_check if col not in df_training.columns]\n",
    "    missing_columns\n",
    "    df_testing_with_label = df_training\n",
    "    #y_train = df_testing_with_label['In-hospital_death'].values.unique()  # Binary target (0 or 1)\n",
    "    y_train = df_testing_with_label.groupby('RecordID')['In-hospital_death'].last().values\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)  # Convert labels to tensor\n",
    "    print(\"len(y_train)\")\n",
    "    print(len(y_train))\n",
    "\n",
    "    df_testing = pd.read_parquet(\"loaded_data/c_patient_data_processed_cluster.parquet\", engine='pyarrow')\n",
    "    df_testing.head()\n",
    "    print(df_testing.columns)\n",
    "    timestamp_count = df_testing.groupby('RecordID')['Time'].nunique()\n",
    "    print(timestamp_count)\n",
    "    df_testing_with_label = df_testing\n",
    "    #y_train = df_testing_with_label['In-hospital_death'].values.unique()  # Binary target (0 or 1)\n",
    "    y_test = df_testing_with_label.groupby('RecordID')['In-hospital_death'].last().values\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)  # Convert labels to tensor\n",
    "    print(\"len(y_test)\")\n",
    "    print(len(y_test))\n",
    "    \n",
    "    # Step 4: Train and evaluate linear probe\n",
    "    print(\"\\n=== Task 2: Train Linear Probe ===\")\n",
    "    linear_model = train_linear_probe(train_embeddings, y_train, num_epochs=50, lr=0.001, batch_size=32)\n",
    "    \n",
    "    linear_results = evaluate_model(linear_model, test_embeddings, y_test)\n",
    "    \n",
    "    # Step 5: Smart aggregation approach\n",
    "    print(\"\\n=== Task 3: Smart Variable Aggregation ===\")\n",
    "    \n",
    "    # Generate per-variable embeddings for a subset of patients to demonstrate\n",
    "    print(\"Generating per-variable embeddings...\")\n",
    "    var_train_emb_file = 'train_variable_embeddings.pth'\n",
    "    var_test_emb_file = 'test_variable_embeddings.pth'\n",
    "    \n",
    "    train_subset = processed_train['RecordID'].unique()\n",
    "    test_subset = processed_test['RecordID'].unique()\n",
    "    \n",
    "    if os.path.exists(var_train_emb_file):\n",
    "        print(\"Loading pre-computed embeddings train...\")\n",
    "        train_var_embeddings = torch.load(var_train_emb_file, weights_only=False)\n",
    "    else:\n",
    "        print(f\"Generating variable embeddings for {len(train_subset)} training patients...\")\n",
    "        train_var_embeddings = generate_variable_embeddings(\n",
    "            processed_train, train_subset, pipeline)\n",
    "        torch.save(train_var_embeddings, var_train_emb_file)\n",
    "\n",
    "    print(processed_train.columns)\n",
    "    print(len(processed_train.columns))\n",
    "    \n",
    "    #if os.path.exists(var_test_emb_file):\n",
    "    #    print(\"Loading pre-computed embeddings test...\")\n",
    "    #    test_var_embeddings = torch.load(var_test_emb_file, weights_only=False)\n",
    "    #else:\n",
    "    print(f\"Generating variable embeddings for {len(test_subset)} test patients...\")\n",
    "    test_var_embeddings = generate_variable_embeddings(processed_test, test_subset, pipeline, checkpoint_file = var_test_emb_file)\n",
    "        #torch.save(test_var_embeddings, var_test_emb_file)\n",
    "    \n",
    "    #print(train_var_embeddings.size())\n",
    "    # Train smart aggregation model\n",
    "    print(\"Training smart aggregation model...\")\n",
    "    smart_model = train_smart_aggregation_model(\n",
    "        train_var_embeddings, y_train,\n",
    "        num_epochs=50, lr=0.001, batch_size=16)\n",
    "    \n",
    "    # Evaluate smart aggregation model\n",
    "    smart_results = evaluate_smart_aggregation_model(\n",
    "        smart_model, test_var_embeddings, y_test)\n",
    "    \n",
    "    # Visualize variable attention weights\n",
    "    print(\"Visualizing variable importance...\")\n",
    "    visualize_attention_weights(smart_results[\"attention_weights\"], feature_names)\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\n=== Performance Comparison ===\")\n",
    "    print(f\"Linear Probe AUC: {linear_results['auc']:.4f}\")\n",
    "    print(f\"Linear Probe AUPRC: {linear_results['auprc']:.4f}\")\n",
    "    print(f\"Smart Aggregation AUC: {smart_results['auc']:.4f}\")\n",
    "    \n",
    "    print(\"Pipeline completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed2a0f-cd94-4afa-b822-05ec85121c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
